# Phase 4: Character & Environment Extraction + Storyboard Planning

## ğŸ“‹ Overview

Phase 4 transforms the Phase 3 screenplay into structured data ready for AI image and video generation. It extracts characters, environments, and creates detailed frame-by-frame storyboard plans.

**Status:** âœ… Complete and ready for integration

**Purpose:** Parse screenplay and create complete visual production data

**ğŸ¬ CRITICAL:** All storyboard frames are **16:9 aspect ratio (1920x1080)** for direct video production. See [ASPECT_RATIO_GUIDE.md](ASPECT_RATIO_GUIDE.md) for full details.

## ğŸ¯ What Phase 4 Does

1. **Character Extraction** - Every unique character with physical descriptions and costumes
2. **Voice Profile Extraction** - Speech patterns, accents, emotional delivery for AI voice generation
3. **Environment Extraction** - Locations with permanent fixtures for "anchor" images
4. **Scene Analysis** - Action beats, props, dialogue segments, complexity analysis
5. **Storyboard Planning** - Frame-by-frame blueprint with intelligent shot selection

## ğŸ“ Directory Structure

```
phase4_extraction/
â”œâ”€â”€ __init__.py              # Package exports
â”œâ”€â”€ graph.py                 # LangGraph workflow orchestrator
â”œâ”€â”€ state.py                 # Phase4State schema
â”œâ”€â”€ models.py                # 12+ Pydantic models
â”œâ”€â”€ utils.py                 # 20+ helper functions
â””â”€â”€ nodes/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ character_extraction.py
    â”œâ”€â”€ voice_profile_extraction.py
    â”œâ”€â”€ environment_extraction.py
    â”œâ”€â”€ scene_analysis.py
    â””â”€â”€ storyboard_planning.py
```

## ğŸ”„ Workflow

```
Phase 3 Screenplay
    â†“
[Node 1] Character Extraction
    â†“
[Node 2] Voice Profile Extraction
    â†“
[Node 3] Environment Extraction
    â†“
[Node 4] Scene Analysis
    â†“
[Node 5] Storyboard Planning
    â†“
JSON Outputs (ready for Phase 5)
```

## ğŸ“Š Key Models

### Character
```python
{
  "character_id": "char_001",
  "name": "ARJUN",
  "full_name": "Inspector Arjun Rao",
  "age": "mid-40s",
  "gender": "male",
  "ethnicity": "Indian",
  "base_physical_description": "...",
  "permanent_features": {...},
  "personality_traits": [...],
  "scenes_appeared": [1, 3, 5, ...],
  "costumes_by_scene": {...},
  "voice_profile": {...},
  "image_generation_prompt": "..."
}
```

### Voice Profile
```python
{
  "accent": "Indian English",
  "voice_characteristics": {
    "pitch": "medium-low",
    "tone": "gravelly",
    "pace": "deliberate"
  },
  "speech_patterns": {...},
  "emotional_variations": {...},
  "dialogue_examples": [...],
  "ai_voice_generation_profile": {...}
}
```

### Environment
```python
{
  "environment_id": "env_001",
  "name": "Arjun's Bedroom",
  "type": "interior",
  "permanent_elements": {
    "walls": "...",
    "floor": "...",
    "furniture": [...],
    "fixtures": [...]
  },
  "lighting_setup": {...},
  "camera_setup": {...},
  "time_variations": {...},
  "image_generation_prompt": "..."
}
```

### Storyboard Frame
```python
{
  "frame_number": 1,
  "shot_type": "establishing",
  "camera_angle": "wide",
  "camera_movement": "static",
  "character_distance": "medium",
  "description": "...",
  "character_present": {...},
  "has_end_frame": false,
  "video_clip": {...},
  "composition": "...",
  "image_generation_note": "..."
}
```

## ğŸ’¾ Output Files

```
outputs/session_YYYYMMDD_HHMMSS/
â””â”€â”€ phase4_extraction/
    â”œâ”€â”€ characters_database.json       # Complete character data
    â”œâ”€â”€ environments_database.json     # Complete environment data
    â”œâ”€â”€ scenes_detailed.json          # â­ Scenes with storyboards
    â”œâ”€â”€ storyboard_summary.json       # Quick reference
    â””â”€â”€ phase4_metadata.json          # Statistics
```

## ğŸ¬ Key Innovations

### 1. Adaptive Frame Counts
Automatically determines optimal number of frames based on:
- Scene duration (longer = more frames)
- Complexity (more action beats = more frames)
- Dialogue density (heavy dialogue = fewer frames)
- Scene type (action vs dialogue)

### 2. Intelligent Storyboard Formats
- **4x1** - Dialogue scenes (4 vertical frames)
- **2x3** - Medium complexity (6 frames)
- **3x3** - Complex scenes (9 frames)
- **4x4** - Very complex (16 frames)
- **Custom** - Mixed formats when needed

### 3. Start + End Frame System
For actions with clear state changes:
```python
# Start frame: Character reaching for phone
# End frame: Character holding phone
# AI video generation interpolates between them
# Result: Smooth 6-8 second video clip
```

### 4. Distance-Based Shot Selection
```python
if character_distance == "far":
    # Face not visible in 3x3 grid
    # Follow with closer shot
    
if character_distance == "close":
    # Face clearly visible
    # Good for dialogue
```

### 5. Voice Consistency Profiles
Maps how each character's voice changes:
- Calm state â†’ measured, controlled
- Stressed state â†’ faster, clipped
- Angry state â†’ lower pitch, threatening
- Tired state â†’ slower, gravelly

## ğŸš€ Usage

### Basic Usage
```python
from phase4_extraction import run_phase4, save_phase4_outputs

# Run Phase 4
final_state = run_phase4(
    screenplay_text=phase3_result['screenplay_text'],
    scene_breakdown=phase3_result['scene_breakdown'],
    screenplay_metadata=phase3_result['screenplay_metadata'],
    session_id="session_123",
    output_directory="./outputs/session_123"
)

# Save outputs
output_paths = save_phase4_outputs(final_state, "./outputs/session_123")
```

### With Historical Data
```python
# If Phase 2 ran (historical story)
final_state = run_phase4(
    screenplay_text=screenplay_text,
    scene_breakdown=scene_breakdown,
    screenplay_metadata=metadata,
    session_id=session_id,
    output_directory=output_dir,
    timeline=phase2_result['timeline'],        # Historical timeline
    key_figures=phase2_result['key_figures'],  # Historical figures
    key_locations=phase2_result['key_locations']
)
```

### Integration with Existing Pipeline
See `INTEGRATION_GUIDE.py` for complete `main.py` update.

## âš™ï¸ Configuration

Phase 4 uses `config.py` for model settings:

```python
MODELS = {
    "phase4": {
        "character_extraction": "gpt-4o",       # Premium for detail
        "voice_extraction": "gpt-4o",           # Premium for analysis
        "environment_extraction": "gpt-4o",     # Premium for detail
        "scene_analysis": "gpt-4o",             # Premium for complexity
        "storyboard_planning": "gpt-4o",        # Premium for creativity
    }
}

TEMPERATURES = {
    "character_extraction": 0.3,      # Structured extraction
    "voice_extraction": 0.4,          # Slightly creative
    "environment_extraction": 0.3,     # Structured extraction
    "scene_analysis": 0.4,            # Analytical
    "storyboard_planning": 0.5,       # Creative planning
}
```

## ğŸ’° Cost & Performance

### Per 30-Scene Screenplay

| Node | Model | Calls | Cost | Time |
|------|-------|-------|------|------|
| Character Extraction | gpt-4o | 1 | $0.05 | 30s |
| Voice Profiles | gpt-4o | 10 chars | $0.30 | 3min |
| Environment Extraction | gpt-4o | 8 envs | $0.20 | 2min |
| Scene Analysis | gpt-4o | 30 | $0.50 | 5min |
| Storyboard Planning | gpt-4o | 30 | $0.60 | 8min |
| **TOTAL** | | | **~$1.65** | **~18min** |

### Cost Optimization
To reduce costs, use `gpt-4o-mini` for some nodes:
```python
MODELS = {
    "phase4": {
        "character_extraction": "gpt-4o-mini",    # $0.40 total
        "voice_extraction": "gpt-4o",             # Keep premium
        "environment_extraction": "gpt-4o-mini",
        "scene_analysis": "gpt-4o-mini",
        "storyboard_planning": "gpt-4o",          # Keep premium
    }
}
```

## ğŸ§ª Testing

Run the test script:
```bash
python test_phase4.py
```

This will:
1. Create sample screenplay
2. Run complete Phase 4 workflow
3. Generate all JSON outputs
4. Display statistics

## ğŸ“ˆ Output Statistics

Typical 30-scene screenplay:

```
Characters extracted: 8-12
Voice profiles: 8-12
Environments: 5-8
Scenes analyzed: 30
Storyboards created: 30
Total frames planned: 150-250
Total video clips: 80-100
```

## ğŸ”— Integration Points

### Input (from Phase 3)
- `screenplay_text` - Complete Fountain screenplay
- `scene_breakdown` - List of scenes with basic info
- `screenplay_metadata` - Page count, duration, etc.

### Optional Input (from Phase 2)
- `timeline` - Historical events
- `key_figures` - Historical figures
- `key_locations` - Historical locations

### Output (to Phase 5)
- `characters_database.json` - For character image generation
- `environments_database.json` - For anchor image generation
- `scenes_detailed.json` - For storyboard image generation
- All data includes AI generation prompts

## ğŸ¨ Phase 5 Preview

Phase 4 outputs are designed for Phase 5:

1. **Character Images** - Use `character.image_generation_prompt`
2. **Environment Anchors** - Use `environment.image_generation_prompt`
3. **Storyboard Frames** - Use `frame.image_generation_note`
4. **Video Clips** - Use `frame.start_frame` + `frame.end_frame`
5. **Voice Audio** - Use `character.voice_profile`

## ğŸ› Troubleshooting

### Import Errors
```python
# If you get import errors, check:
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
from config import get_llm_config
```

### Missing Environment Variables
```bash
# Make sure .env is loaded
OPENAI_API_KEY=sk-proj-...
```

### LangGraph State Errors
```python
# Node names must NOT match state keys
workflow.add_node("extract_characters", character_extraction_node)
# NOT: workflow.add_node("characters_database", character_extraction_node)
```

## ğŸ“š Documentation

- Full implementation guide: See attached documents
- Integration guide: `INTEGRATION_GUIDE.py`
- Model specifications: `models.py`
- Utility functions: `utils.py`

## ğŸ¯ Next Steps

1. âœ… Phase 4 complete - Run test
2. ğŸ“ Update `main.py` with integration code
3. ğŸ§ª Test with full pipeline
4. ğŸ¨ Begin Phase 5 implementation

---

## ğŸ“ 16:9 Aspect Ratio Requirement

**CRITICAL:** Every storyboard frame image MUST be exactly 16:9 aspect ratio (1920Ã—1080 pixels).

### Why 16:9?
- âœ… Standard widescreen video format
- âœ… Direct use in video generation (no cropping)
- âœ… Platform compatibility (YouTube, streaming)
- âœ… Professional cinematic output

### Implementation
All image generation prompts include:
```
"16:9 aspect ratio"
"1920x1080 resolution"
"widescreen cinematic frame"
"NO letterboxing, NO pillarboxing"
```

### Frame Data
Every frame includes:
```python
{
  "aspect_ratio": "16:9",
  "resolution": "1920x1080",
  "widescreen": True,
  # ... other fields
}
```

**ğŸ“– See [ASPECT_RATIO_GUIDE.md](ASPECT_RATIO_GUIDE.md) for complete documentation.**

---

## ğŸ“ Notes

- All nodes use structured outputs (Pydantic models)
- Designed for production use with error handling
- Outputs are JSON for easy Phase 5 integration
- Maintains character/environment consistency
- Ready for AI image/video generation

---

**Phase 4 Status:** âœ… Complete and production-ready
**Ready for:** Integration with Phases 1-3 and Phase 5 development
